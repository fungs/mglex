#!/usr/bin/env python3

u"""
 This is the main program which takes a raw (negatively log-scaled) likelihood matrix and a class soft class assignment
 matrix (responsibility) and corresponding weights, e.g. sequence lengths, Fall all input, each row corresponds to one
 datum  and each column corresponds to a class. For each class, the likelihood distribution is evaluated and a statistic
 of how well the null hypothesis (positive class) distribution is separated from the alternative hypothesis distribution
 (negative class/other data). The statistic can aid in comparing and selecting appropriate models which transform raw
 data into observation likelihoods.

Usage:
  classify-likelihood  (--help | --version)
  classify-likelihood  (--likelihood <file>) (--responsibility <file>) (--weight <file>)

  -h, --help                           Show this screen
  -v, --version                        Show version
  -l <file>, --likelihood <file>       Likelihood matrix; default standard input
  -r <file>, --responsibility <file>   Responsibility (weight) matrix file
  -w <file>, --weight <file>           Weights (sequence length) file
"""

# TODO: support multiple arguments of the same kind, like multiple label input data

__author__ = "johannes.droege@uni-duesseldorf.de"
__version__ = "bla"

import common
import numpy as np
import sys
from itertools import count


def twoclass_separability(like, weights_null, weights_alt):
    # TODO: do cumulative arrays and array arithmetics
    like = -like
    order = np.argsort(like, axis=0)

    error = 0.0
    wn_cumulative = common.large_float_type(weights_null.sum())
    wa_cumulative = common.large_float_type(0.0)

    l_last = 0.0
    step_size = 0.0
    width = 0.0
    for l, wn, wa, step in zip(like[order], weights_null[order], weights_alt[order], count()):  # TODO: stop loop when wn_cumulative == 0.0
        step_size = l - l_last
        if step_size > 0.0:
            height = wn_cumulative * wa_cumulative
            box = height * width
            error += box
            width = step_size
            #print("Step %i: like=%.2f, wn_cum=%f, wa_cum=%f, height=%f, width=%f, box=%f, error=%f" % (step, l, wn_cumulative, wa_cumulative, height, width, box, error))

        wn_cumulative -= wn
        wa_cumulative += wa
        l_last = l

    common.assert_approx_equal(wa_cumulative, 1.0)
    height = wn_cumulative * wa_cumulative
    box = height * width
    error += box
    error /= l_last

    return error


if __name__ == "__main__":
    from docopt import docopt
    argument = docopt(__doc__, version=__version__)
    common.handle_broken_pipe()


    # load input
    likelihood_filename = argument["--likelihood"]
    if likelihood_filename:
        likelihood = common.load_probmatrix_file(likelihood_filename)
    else:
        likelihood = common.load_probmatrix(sys.stdin)

    responsibility = np.exp(common.load_probmatrix_file(argument["--responsibility"]))
    weight = common.load_seqlens_file(argument["--weight"])

    #normalization = weight.sum(dtype=common.large_float_type)  # check for overflow
    n, c = likelihood.shape
    scores = np.zeros(c, dtype=common.large_float_type)
    sizes = np.zeros(c, dtype=common.large_float_type)

    for i in range(c):
        r = responsibility[:, (i,)]
        wn = r * weight
        wn_sum = wn.sum()
        wn /= wn_sum
        wa = (1.0 - r) * weight
        wa /= wa.sum()
        l = likelihood[:, i]
        scores[i] = twoclass_separability(l, wn, wa)
        sizes[i] = wn_sum

    classpriors = sizes/sizes.sum()
    sys.stdout.write("%f\n" % np.sqrt(np.sum((scores**2)*classpriors)))
